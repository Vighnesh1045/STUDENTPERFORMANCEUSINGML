# -*- coding: utf-8 -*-
"""vighnesh_stream_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NVlLSuR47PMiL2qu5st211NvXnHUzahv
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the data
df = pd.read_excel("/content/studentmarksheetupdated.xlsx")
df

df.info()

# Combine "Commerce" and "Arts" into a single category "Commerce/Arts"
df['Branch'] = df['Branch'].replace({'Commerce': 'Commerce/Arts', 'Arts': 'Commerce/Arts'})

# Extract features and target
X = df.drop(['Branch', 'Names'], axis=1)  # Drop 'Name' column
y = df['Branch']

# One-hot encode 'Gender' column
encoder = OneHotEncoder(sparse=False, drop='first')  # Drop first to avoid multicollinearity
X_encoded = pd.concat([X, pd.DataFrame(encoder.fit_transform(X[['Gender']]), columns=['Gender_N'])], axis=1)

# Drop the original 'Gender' column
X_encoded = X_encoded.drop('Gender', axis=1)

# Display column names in X
print(X.columns)

# Min-Max scale subject columns
scaler = MinMaxScaler()
subject_columns = ['Maths', 'Physics', 'Chemistry', 'English', 'Biology', 'Economics', 'History', 'Civics']

X_encoded[subject_columns] = scaler.fit_transform(X[subject_columns])

# # Min-Max scale subject columns
# scaler = MinMaxScaler()
# X_encoded[['Maths', 'Physics', 'Chemistry', 'English', 'Biology', 'Economics', 'History', 'Civics']] = scaler.fit_transform(X[['Maths', 'Physics', 'Chemistry', 'English', 'Biology', 'Economics', 'History', 'Civics']])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# Train the Random Forest model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy}')





# Hyperparameter tuning using GridSearchCV
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
print(f'Best Hyperparameters: {best_params}')

best_model = grid_search.best_estimator_
predictions = best_model.predict(X_test)

# Evaluate the best model
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy with best model: {accuracy}')

# Display the confusion matrix
conf_matrix = confusion_matrix(y_test, predictions)
print(f'Confusion Matrix:\n{conf_matrix}')

# Display the classification report
class_report = classification_report(y_test, predictions)
print(f'Classification Report:\n{class_report}')

# Display feature importances
feature_importances = pd.DataFrame({'Feature': X_test.columns, 'Importance': best_model.feature_importances_})
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)
print('Feature Importances:')
print(feature_importances)

# Assuming you have a single data point in a dictionary format
# Replace the values in the dictionary with your actual data
new_data_point = {
    'Gender_N': 0,  # Update this value according to your data
    'Maths': 45,
    'Physics': 60,
    'Chemistry': 58,
    'English': 75,
    'Biology': 62,
    'Economics': 85,
    'History': 78,
    'Civics': 80
}

# Convert the data point to a DataFrame
new_data_df = pd.DataFrame([new_data_point])

# Reorder the columns to match the order during training
new_data_encoded = new_data_df[X_train.columns]

# Min-Max scale subject columns
new_data_encoded[subject_columns] = scaler.transform(new_data_df[subject_columns])

# Use the best model for prediction on the single data point
prediction = best_model.predict(new_data_encoded)

# Print or use the prediction as needed
print(f'Predicted Branch: {prediction[0]}')

import pickle

# Assuming `best_model` is your trained RandomForestClassifier
with open('stream_predict_final.pkl', 'wb') as file:
    pickle.dump(best_model, file)



